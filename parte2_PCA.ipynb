{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a021c4c2d228a9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T01:17:58.812581Z",
     "start_time": "2024-06-12T01:17:53.484939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados iniciais:\n",
      "        Category  Rating  Rating Count Installs  Free  Price  Size  \\\n",
      "0      Adventure     0.0           0.0      10+  True    0.0   10M   \n",
      "1          Tools     4.4          64.0   5,000+  True    0.0  2.9M   \n",
      "2   Productivity     0.0           0.0      50+  True    0.0  3.7M   \n",
      "3  Communication     5.0           5.0      10+  True    0.0  1.8M   \n",
      "4          Tools     0.0           0.0     100+  True    0.0  6.2M   \n",
      "\n",
      "  Minimum Android Content Rating  Ad Supported  In App Purchases  \\\n",
      "0      7.1 and up       Everyone         False             False   \n",
      "1      5.0 and up       Everyone          True             False   \n",
      "2    4.0.3 and up       Everyone         False             False   \n",
      "3    4.0.3 and up       Everyone          True             False   \n",
      "4      4.1 and up       Everyone         False             False   \n",
      "\n",
      "   Editors Choice  \n",
      "0           False  \n",
      "1           False  \n",
      "2           False  \n",
      "3           False  \n",
      "4           False  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Category          8000 non-null   object \n",
      " 1   Rating            7930 non-null   float64\n",
      " 2   Rating Count      7930 non-null   float64\n",
      " 3   Installs          7999 non-null   object \n",
      " 4   Free              8000 non-null   bool   \n",
      " 5   Price             8000 non-null   float64\n",
      " 6   Size              8000 non-null   object \n",
      " 7   Minimum Android   7979 non-null   object \n",
      " 8   Content Rating    8000 non-null   object \n",
      " 9   Ad Supported      8000 non-null   bool   \n",
      " 10  In App Purchases  8000 non-null   bool   \n",
      " 11  Editors Choice    8000 non-null   bool   \n",
      "dtypes: bool(4), float64(3), object(5)\n",
      "memory usage: 531.4+ KB\n",
      "None\n",
      "Valores ausentes antes da imputação:\n",
      "Category             0\n",
      "Rating              70\n",
      "Rating Count        70\n",
      "Installs             1\n",
      "Free                 0\n",
      "Price                0\n",
      "Size                 0\n",
      "Minimum Android     21\n",
      "Content Rating       0\n",
      "Ad Supported         0\n",
      "In App Purchases     0\n",
      "Editors Choice       0\n",
      "dtype: int64\n",
      "Exemplos de valores na coluna 'Installs' após a conversão:\n",
      "0       10\n",
      "1     5000\n",
      "2       50\n",
      "3       10\n",
      "4      100\n",
      "5       50\n",
      "6     1000\n",
      "7      500\n",
      "8       10\n",
      "9    50000\n",
      "Name: Installs, dtype: Int64\n",
      "Valores ausentes após remoção de linhas com 'Installs' nulos:\n",
      "Category             0\n",
      "Rating              69\n",
      "Rating Count        69\n",
      "Installs             0\n",
      "Free                 0\n",
      "Price                0\n",
      "Size                 0\n",
      "Minimum Android     21\n",
      "Content Rating       0\n",
      "Ad Supported         0\n",
      "In App Purchases     0\n",
      "Editors Choice       0\n",
      "dtype: int64\n",
      "Content Mapping  {'Everyone': 0, 'Everyone 10+': 1, 'Mature 17+': 2, 'Teen': 3} \n",
      "Category Mapping  {'Action': 0, 'Adventure': 1, 'Arcade': 2, 'Art & Design': 3, 'Auto & Vehicles': 4, 'Beauty': 5, 'Board': 6, 'Books & Reference': 7, 'Business': 8, 'Card': 9, 'Casino': 10, 'Casual': 11, 'Comics': 12, 'Communication': 13, 'Dating': 14, 'Education': 15, 'Educational': 16, 'Entertainment': 17, 'Events': 18, 'Finance': 19, 'Food & Drink': 20, 'Health & Fitness': 21, 'House & Home': 22, 'Libraries & Demo': 23, 'Lifestyle': 24, 'Maps & Navigation': 25, 'Medical': 26, 'Music': 27, 'Music & Audio': 28, 'News & Magazines': 29, 'Parenting': 30, 'Personalization': 31, 'Photography': 32, 'Productivity': 33, 'Puzzle': 34, 'Racing': 35, 'Role Playing': 36, 'Shopping': 37, 'Simulation': 38, 'Social': 39, 'Sports': 40, 'Strategy': 41, 'Tools': 42, 'Travel & Local': 43, 'Trivia': 44, 'Video Players & Editors': 45, 'Weather': 46, 'Word': 47}\n",
      "Tamanho atual do dataframe: (7999, 12)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree, export_graphviz\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "import os\n",
    "from IPython.display import Image\n",
    "\n",
    "# Carregar o dataset\n",
    "data = pd.read_csv('Data/Google-Playstore.csv', nrows=8000)\n",
    "\n",
    "# Remover colunas indesejadas\n",
    "data = data.drop(['App Name', 'App Id', 'Minimum Installs', 'Maximum Installs', 'Currency',\n",
    "                  'Developer Id', 'Developer Website', 'Developer Email', 'Released',\n",
    "                  'Last Updated', 'Privacy Policy', 'Scraped Time'], axis=1)\n",
    "\n",
    "# Inspecionar os primeiros registros e verificar valores ausentes\n",
    "print(\"Dados iniciais:\")\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "print(\"Valores ausentes antes da imputação:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Remover linhas onde a variável alvo 'Installs' é nula\n",
    "data = data.dropna(subset=['Installs'])\n",
    "\n",
    "# Tratar a coluna 'Installs'\n",
    "data['Installs'] = data['Installs'].str.replace('[+,]', '', regex=True)\n",
    "data['Installs'] = pd.to_numeric(data['Installs'], errors='coerce').astype('Int64')\n",
    "\n",
    "print(\"Exemplos de valores na coluna 'Installs' após a conversão:\")\n",
    "print(data['Installs'].head(10))\n",
    "\n",
    "print(\"Valores ausentes após remoção de linhas com 'Installs' nulos:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "def handle_missing_values(df):\n",
    "    df['Category'].fillna(df['Category'].mode()[0], inplace=True)\n",
    "    df['Rating'].fillna(df['Rating'].mean(), inplace=True)\n",
    "    df['Rating Count'].fillna(df['Rating Count'].mean(), inplace=True)\n",
    "    df['Free'].fillna(True, inplace=True)\n",
    "    df['Price'].fillna(0.0, inplace=True)\n",
    "    df['Size'] = df['Size'].apply(size_to_mb)\n",
    "    df['Size'].fillna(df['Size'].mean(), inplace=True)\n",
    "    df['Minimum Android'].fillna(df['Minimum Android'].mode()[0], inplace=True)\n",
    "    df['Content Rating'].fillna(df['Content Rating'].mode()[0], inplace=True)\n",
    "    df['Ad Supported'].fillna(True, inplace=True)\n",
    "    df['In App Purchases'].fillna(False, inplace=True)\n",
    "    df['Editors Choice'].fillna(False, inplace=True)\n",
    "\n",
    "def size_to_mb(size):\n",
    "    if pd.isna(size):\n",
    "        return np.nan\n",
    "    if isinstance(size, str):\n",
    "        if 'M' in size or 'm' in size:\n",
    "            return float(size.replace('M', '').replace('m', '').replace(',', '.'))\n",
    "        elif 'K' in size or 'k' in size:\n",
    "            return float(size.replace('K', '').replace('k', '').replace(',', '.')) / 1024\n",
    "        elif 'G' in size or 'g' in size:\n",
    "            return float(size.replace('G', '').replace('g', '').replace(',', '.')) * 1024\n",
    "    return np.nan\n",
    "\n",
    "def parse_android_version(version):\n",
    "    if pd.isna(version):\n",
    "        return np.nan\n",
    "    if 'Varies with device' in version:\n",
    "        return np.nan\n",
    "    if 'and up' in version:\n",
    "        version = version.replace('and up', '').strip()\n",
    "    if '-' in version:\n",
    "        version = version.split('-')[0].strip()\n",
    "    version = version.replace('W', '').strip()\n",
    "    try:\n",
    "        return float(version)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "handle_missing_values(data)\n",
    "data['Minimum Android'] = data['Minimum Android'].apply(parse_android_version)\n",
    "mean_android_version = data['Minimum Android'].mean()\n",
    "data['Minimum Android'].fillna(mean_android_version, inplace=True)\n",
    "\n",
    "data['Rating Count'] = data['Rating Count'].astype(int)\n",
    "data['Minimum Android'] = [int(x * 10) / 10 for x in data['Minimum Android']]\n",
    "\n",
    "label_encoder_category = LabelEncoder()\n",
    "label_encoder_content_rating = LabelEncoder()\n",
    "data['Category'] = label_encoder_category.fit_transform(data['Category'])\n",
    "category_mapping = dict(zip(label_encoder_category.classes_, label_encoder_category.transform(label_encoder_category.classes_)))\n",
    "data['Content Rating'] = label_encoder_content_rating.fit_transform(data['Content Rating'])\n",
    "content_mapping = dict(zip(label_encoder_content_rating.classes_, label_encoder_content_rating.transform(label_encoder_content_rating.classes_)))\n",
    "\n",
    "print(\"Content Mapping \", content_mapping, \"\\nCategory Mapping \", category_mapping)\n",
    "\n",
    "# Preparação dos dados\n",
    "X = data[['Category', 'Rating','Rating Count', 'Free','Price','Size','Minimum Android','Content Rating', 'Ad Supported','In App Purchases','Editors Choice']]\n",
    "y = data['Installs']\n",
    "\n",
    "# Aplicar PCA para redução de dimensionalidade\n",
    "pca = PCA(n_components=5, svd_solver='auto')\n",
    "X_reduced = pca.fit_transform(X)\n",
    "\n",
    "# Dividir o dataset em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Função para avaliar o modelo\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"R^2: {r2:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\\n\")\n",
    "    return model\n",
    "\n",
    "print(\"Tamanho atual do dataframe:\", data.shape)\n",
    "\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Linear Regression\n",
      "R^2: 0.7596\n",
      "MAE: 117286.0039\n",
      "MSE: 1614355117464.8625\n",
      "RMSE: 1270572.7517\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Avaliar modelos e armazenar no dicionário\n",
    "models['Linear Regression'] = evaluate_model('Linear Regression', LinearRegression(), X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T01:17:58.840801Z",
     "start_time": "2024-06-12T01:17:58.817873Z"
    }
   },
   "id": "b0cee7269e5164f0",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Ridge Regression\n",
      "R^2: 0.7596\n",
      "MAE: 117285.8984\n",
      "MSE: 1614355108216.0405\n",
      "RMSE: 1270572.7481\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models['Ridge Regression'] = evaluate_model('Ridge Regression', Ridge(alpha=1.0), X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T01:17:58.864481Z",
     "start_time": "2024-06-12T01:17:58.845176Z"
    }
   },
   "id": "e4518e20d3ba27ea",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Lasso Regression\n",
      "R^2: 0.7596\n",
      "MAE: 117285.8384\n",
      "MSE: 1614355112512.4182\n",
      "RMSE: 1270572.7498\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models['Lasso Regression'] = evaluate_model('Lasso Regression', Lasso(alpha=1.0), X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T01:17:58.893498Z",
     "start_time": "2024-06-12T01:17:58.867201Z"
    }
   },
   "id": "2f42d821b375814b",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVR (linear kernel)\n",
      "R^2: 0.6401\n",
      "MAE: 100358.0172\n",
      "MSE: 2416846885466.7373\n",
      "RMSE: 1554621.1389\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models['SVR (linear kernel)'] = evaluate_model('SVR (linear kernel)', SVR(kernel='linear'), X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T01:19:30.354573Z",
     "start_time": "2024-06-12T01:17:59.546739Z"
    }
   },
   "id": "8119d05e1dfe29a7",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SVR (rbf kernel)\n",
      "R^2: -0.0032\n",
      "MAE: 146634.7652\n",
      "MSE: 6736969966256.6201\n",
      "RMSE: 2595567.3689\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models['SVR (rbf kernel)'] = evaluate_model('SVR (rbf kernel)', SVR(kernel='rbf'), X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T01:19:36.192151Z",
     "start_time": "2024-06-12T01:19:30.359337Z"
    }
   },
   "id": "381782f186ac9368",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: K-NN\n",
      "R^2: 0.6011\n",
      "MAE: 112260.2300\n",
      "MSE: 2678764508613.6504\n",
      "RMSE: 1636693.1626\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models['K-NN'] = evaluate_model('K-NN', KNeighborsRegressor(n_neighbors=2), X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T01:19:36.228926Z",
     "start_time": "2024-06-12T01:19:36.195212Z"
    }
   },
   "id": "8e18ee578b422123",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Decision Tree\n",
      "R^2: 0.2079\n",
      "MAE: 123362.4926\n",
      "MSE: 5319584436512.9395\n",
      "RMSE: 2306422.4324\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models['Decision Tree'] = evaluate_model('Decision Tree', DecisionTreeRegressor(), X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T01:19:36.355250Z",
     "start_time": "2024-06-12T01:19:36.233047Z"
    }
   },
   "id": "8cfca374f027ef4e",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "R^2: 0.8006\n",
      "MAE: 100746.3879\n",
      "MSE: 1339001635668.6270\n",
      "RMSE: 1157152.3822\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models['Random Forest'] = evaluate_model('Random Forest', RandomForestRegressor(n_estimators=200), X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T01:20:04.134560Z",
     "start_time": "2024-06-12T01:19:37.341258Z"
    }
   },
   "id": "ebd6880d69f262ba",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Neural Network (single layer)\n",
      "R^2: 0.7583\n",
      "MAE: 101724.9721\n",
      "MSE: 1623148367220.7256\n",
      "RMSE: 1274028.4013\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models['Neural Network (single layer)'] = evaluate_model('Neural Network (single layer)', MLPRegressor(hidden_layer_sizes=(10000,), max_iter=10000), X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T01:21:40.154501Z",
     "start_time": "2024-06-12T01:20:04.137392Z"
    }
   },
   "id": "84380a440879fb40",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Neural Network (multi layer)\n",
      "R^2: 0.7575\n",
      "MAE: 101445.0298\n",
      "MSE: 1628703827308.0488\n",
      "RMSE: 1276206.8121\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models['Neural Network (multi layer)'] = evaluate_model('Neural Network (multi layer)', MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=10000), X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T01:21:44.810024Z",
     "start_time": "2024-06-12T01:21:40.158671Z"
    }
   },
   "id": "46050bcb3ef4277f",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ivani\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but SVR was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 11 features, but SVR is expecting 5 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 86\u001B[0m\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;241m==\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLinear Regression\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRidge Regression\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLasso Regression\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLogistic Regression\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     85\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m---> 86\u001B[0m     prediction \u001B[38;5;241m=\u001B[39m predict_new_app(model, new_app_df)\n\u001B[0;32m     87\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrevisão de \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInstalls\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m para a nova app \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGakondo\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mprediction[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.0f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     88\u001B[0m \u001B[38;5;66;03m#Imprimir tamanho do dataframe\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[25], line 78\u001B[0m, in \u001B[0;36mpredict_new_app\u001B[1;34m(model, new_app_df)\u001B[0m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict_new_app\u001B[39m(model, new_app_df):\n\u001B[0;32m     77\u001B[0m     \u001B[38;5;66;03m# Prever a variável alvo\u001B[39;00m\n\u001B[1;32m---> 78\u001B[0m     prediction \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(new_app_df)\n\u001B[0;32m     79\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m prediction\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:433\u001B[0m, in \u001B[0;36mBaseLibSVM.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    417\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m    418\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Perform regression on samples in X.\u001B[39;00m\n\u001B[0;32m    419\u001B[0m \n\u001B[0;32m    420\u001B[0m \u001B[38;5;124;03m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    431\u001B[0m \u001B[38;5;124;03m        The predicted values.\u001B[39;00m\n\u001B[0;32m    432\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 433\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_for_predict(X)\n\u001B[0;32m    434\u001B[0m     predict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sparse_predict \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sparse \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dense_predict\n\u001B[0;32m    435\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m predict(X)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:613\u001B[0m, in \u001B[0;36mBaseLibSVM._validate_for_predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    610\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    612\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel):\n\u001B[1;32m--> 613\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(\n\u001B[0;32m    614\u001B[0m         X,\n\u001B[0;32m    615\u001B[0m         accept_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    616\u001B[0m         dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat64,\n\u001B[0;32m    617\u001B[0m         order\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    618\u001B[0m         accept_large_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    619\u001B[0m         reset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    620\u001B[0m     )\n\u001B[0;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sparse \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m sp\u001B[38;5;241m.\u001B[39misspmatrix(X):\n\u001B[0;32m    623\u001B[0m     X \u001B[38;5;241m=\u001B[39m sp\u001B[38;5;241m.\u001B[39mcsr_matrix(X)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:588\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    585\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    587\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m--> 588\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_n_features(X, reset\u001B[38;5;241m=\u001B[39mreset)\n\u001B[0;32m    590\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:389\u001B[0m, in \u001B[0;36mBaseEstimator._check_n_features\u001B[1;34m(self, X, reset)\u001B[0m\n\u001B[0;32m    386\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m    388\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_features \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_:\n\u001B[1;32m--> 389\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    390\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX has \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_features\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features, but \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    391\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis expecting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features as input.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    392\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: X has 11 features, but SVR is expecting 5 features as input."
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "def preprocess_new_app(new_app):\n",
    "    # Verificar se new_app é um DataFrame, se não, converter para DataFrame\n",
    "    if not isinstance(new_app, pd.DataFrame):\n",
    "        new_app = pd.DataFrame([new_app], columns=X.columns)\n",
    "\n",
    "    # Preencher valores ausentes na nova aplicação\n",
    "    handle_missing_values(new_app)\n",
    "\n",
    "    # Tratar a coluna 'Size'\n",
    "    new_app['Size'] = new_app['Size'].apply(size_to_mb)\n",
    "\n",
    "    # Tratar a coluna 'Minimum Android'\n",
    "    new_app['Minimum Android'] = new_app['Minimum Android'].apply(parse_android_version)\n",
    "    new_app['Minimum Android'] = [int(x * 10) / 10 for x in new_app['Minimum Android']]\n",
    "\n",
    "    # Codificar variáveis categóricas\n",
    "    new_app['Category'] = new_app['Category'].apply(lambda x: category_mapping.get(x, -1))\n",
    "    new_app['Content Rating'] = new_app['Content Rating'].apply(lambda x: content_mapping.get(x, -1))\n",
    "\n",
    "    # Verificar se há valores não reconhecidos e substituí-los por uma categoria válida (opcional)\n",
    "    new_app['Category'] = new_app['Category'].replace(-1, category_mapping['Tools'])\n",
    "    new_app['Content Rating'] = new_app['Content Rating'].replace(-1, content_mapping['Everyone'])\n",
    "\n",
    "    # Aplicar PCA para redução de dimensionalidade\n",
    "    new_app_reduced = pca.transform(new_app)\n",
    "\n",
    "    return new_app_reduced\n",
    "\n",
    "\n",
    "def predict_installs(new_app_data):\n",
    "    # Pré-processar os dados da nova aplicação\n",
    "    new_app_processed = preprocess_new_app(new_app_data)\n",
    "\n",
    "    # Previsões para cada modelo\n",
    "    predictions = {}\n",
    "    for model_name, model in models.items():\n",
    "        prediction = model.predict(new_app_processed)\n",
    "        predictions[model_name] = prediction[0]\n",
    "\n",
    "    # Imprimir previsões\n",
    "    for model_name, prediction in predictions.items():\n",
    "        print(f\"{model_name}: {prediction:.0f} installs\")\n",
    "\n",
    "\n",
    "# Exemplo de dados de uma nova aplicação\n",
    "new_app_example = {\n",
    "    'Category': 33,  # Exemplo de categoria\n",
    "    'Rating': 4.3,  # Exemplo de avaliação\n",
    "    'Rating Count': 241000,  # Exemplo de contagem de avaliações\n",
    "    'Free': True,  # Se a aplicação é gratuita ou não\n",
    "    'Price': 0.0,  # Preço da aplicação\n",
    "    'Size': 3,  # Tamanho da aplicação\n",
    "    'Minimum Android': 10,  # Versão mínima do Android\n",
    "    'Content Rating': 0,  # Classificação de conteúdo\n",
    "    'Ad Supported': False,  # Se a aplicação tem suporte a anúncios\n",
    "    'In App Purchases': True,  # Se a aplicação tem compras no aplicativo\n",
    "    'Editors Choice': True  # Se a aplicação é escolha do editor\n",
    "}\n",
    "\n",
    "# Converter exemplo de nova aplicação para DataFrame\n",
    "new_app_df = pd.DataFrame([new_app_example])\n",
    "\n",
    "# Prever o número de instalações para a nova aplicação\n",
    "predict_installs(new_app_df)'''\n",
    "\n",
    "#Carregar o ficheiro CSV da nova app\n",
    "new_app_df = pd.read_csv('new_app_example.csv') \n",
    "\n",
    "\n",
    "#Remover colunas não presentes nos dados de treino\n",
    "new_app_df = new_app_df[X.columns]\n",
    "\n",
    "#Função para prever a variável alvo para uma nova app\n",
    "def predict_new_app(model, new_app_df):\n",
    "    # Prever a variável alvo\n",
    "    prediction = model.predict(new_app_df)\n",
    "    return prediction\n",
    "\n",
    "#Fazer a previsão utilizando o pipeline treinado anteriormente\n",
    "\n",
    "for name, model in models.items():\n",
    "    prediction = predict_new_app(model, new_app_df)\n",
    "    print(f\"Previsão de 'Installs' para a nova app 'Gakondo': {prediction[0]:.0f}\")\n",
    "#Imprimir tamanho do dataframe\n",
    "print(\"Tamanho atual do dataframe:\", data.shape)"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-12T01:39:58.446082Z",
     "start_time": "2024-06-12T01:39:58.092648Z"
    }
   },
   "id": "initial_id",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T01:21:46.568905Z",
     "start_time": "2024-06-12T01:21:46.568905Z"
    }
   },
   "id": "d8eb3dc40d6c7a3f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
